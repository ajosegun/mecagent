# GenCAD-Code Baseline: Image-to-CAD-Code Generation

This repository provides a reproducible baseline for the **image-to-code** task using the [CADCODER/GenCAD-Code](https://huggingface.co/datasets/CADCODER/GenCAD-Code) dataset. The goal is to generate valid CADQuery code from images of CAD models, using modern vision-language models and robust evaluation metrics.

---

## Table of Contents

- [Project Structure](#project-structure)
- [Setup](#setup)
- [Dataset Handling](#dataset-handling)
- [Training & Evaluation](#training--evaluation)
- [Evaluation Metrics](#evaluation-metrics)
- [Testing](#testing)
- [Results & Logs](#results--logs)
- [Customization](#customization)
- [References](#references)

---

## Project Structure

```
src/
  config.py                # Configuration loading from .env
  utils/
    gencad_dataset.py      # Dataset loading, preprocessing, saving/loading
    logging.py             # Logger setup
  metrics/
    valid_syntax_rate.py   # Valid Syntax Rate metric
    best_iou.py            # Best IOU metric
  scripts/
    baseline/
      train.py             # Baseline model training
      evaluate.py          # Baseline evaluation and metrics
      predict.py           # Inference script
      cad_query_eval.py    # Metric usage examples
    __init__.py            # Model/tokenizer loader
tests/
  test_gencad_dataset.py   # Dataset and preprocessing tests
  test_baseline_model.py   # Model forward test
.env                       # Environment variables (paths, cache)
```

---

## Setup

1. **Clone the repository and install dependencies:**

   ```sh
   uv pip install -r requirements.txt
   ```

   Or manually:

   ```sh
   uv add torch transformers datasets Pillow pytest numpy python-dotenv
   ```

2. **Configure environment variables:**

   Edit `.env` to set paths for cache, dataset, and output directories. Example:

   ```properties
   HF_DATASETS_CACHE="/Volumes/BIG-DATA/HUGGINGFACE_CACHE"
   BASELINE_DATASET_PATH="data/dataset/baseline"
   BASELINE_OUT_DIR="data/results/baseline/blip_gencad_results"
   BASELINE_METRICS_DIR="data/metrics/baseline"
   IMPROVED_OUT_DIR="data/results/improved/blip_gencad_results"
   IMPROVED_METRICS_DIR="data/metrics/improved"
   ```

---

## Dataset Handling

- **Loading:**  
  The dataset is loaded and preprocessed using `src/utils/gencad_dataset.py`.  
  Preprocessing includes image feature extraction and code tokenization using BLIP.

- **Preprocessing & Caching:**  
  Preprocessed datasets are saved to disk for fast reloads.

  ```python
  from src.utils.gencad_dataset import preprocess_ds, load_preprocessed_dataset
  dataset = preprocess_ds(tokenizer, processor, dataset_path)
  # or
  dataset = load_preprocessed_dataset(dataset_path)
  ```

---

## Training & Evaluation

### **Training**

Train the baseline BLIP model on the GenCAD dataset:

```sh
uv run python -m src.scripts.baseline.train
```

- Uses BLIP (Salesforce/blip-image-captioning-large) as the backbone.
- Training/evaluation splits and parameters are controlled via `.env` and `src/config.py`.

### **Evaluation**

Evaluate the trained model and compute metrics:

```sh
uv run python -m src.scripts.baseline.evaluate
```

- Decodes predictions and computes Valid Syntax Rate and IOU.
- Saves metrics to the configured directory.

---

## Evaluation Metrics

Two main metrics are used:

1. **Valid Syntax Rate:**  
   Measures the percentage of generated code samples that execute without errors.

   ```python
   from src.metrics.valid_syntax_rate import evaluate_syntax_rate_simple
   vsr = evaluate_syntax_rate_simple(generated_codes)
   print("Valid Syntax Rate:", vsr)
   ```

2. **Best IOU:**  
   Compares the similarity between meshes generated by predicted and reference code.

   ```python
   from src.metrics.best_iou import get_iou_best
   iou = get_iou_best(predicted_code, reference_code)
   print("IOU:", iou)
   ```

See [`src/scripts/baseline/evaluate.py`](src/scripts/baseline/evaluate.py) for usage examples.

---

## Testing

Run all tests with:

```sh
pytest tests/
```

- Tests cover dataset loading, preprocessing, and model forward passes.

---

## Results & Logs

- Training and evaluation logs are saved to the output directories specified in `.env`.
- Metrics are saved as text files in the metrics directory.

---

## Customization

- **Model:**  
  Swap out BLIP for other vision-language models by editing `src/scripts/baseline/__init__.py`.
- **Dataset:**  
  Adjust splits or preprocessing in `src/utils/gencad_dataset.py`.
- **Metrics:**  
  Add or modify metrics in `src/metrics/`.

---

## References

- [CADCODER/GenCAD-Code Dataset](https://huggingface.co/datasets/CADCODER/GenCAD-Code)
- [BLIP: Bootstrapped Language-Image Pretraining](https://github.com/salesforce/BLIP)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- [Hugging Face Datasets](https://huggingface.co/docs/datasets/index)
